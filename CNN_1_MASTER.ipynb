{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_1_MASTER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauraredmondson/nma-eggplant-cobra/blob/master/CNN_1_MASTER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL3Qb9vE38Yz",
        "colab_type": "text"
      },
      "source": [
        "CNN\n",
        "\n",
        "- import modules\n",
        "- get images and labels\n",
        "- preprocess images and labels\n",
        "- build and compile the network\n",
        "- train network\n",
        "- test network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6unX72a3UrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de37ea9b-121d-40c4-c8d7-fa1a4204a1d9"
      },
      "source": [
        "# import modules\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.io import loadmat\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmNEW18c5S6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import images\n",
        "\n",
        "fname = \"kay_images.npz\"\n",
        "if not os.path.exists(fname):\n",
        "  !wget -qO $fname https://osf.io/ymnjv/download\n",
        "\n",
        "with np.load(fname) as dobj:\n",
        "    dat = dict(**dobj)  # 'dat' is the object we care about!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4fUHAGz5hyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(dat.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3S2miWV5_Ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import labels\n",
        "\n",
        "test = loadmat('y_test.mat')\n",
        "train = loadmat('y_train.mat')\n",
        "print(train.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO2qX3KS8291",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract variables\n",
        "\n",
        "y_train = train[\"y_train\"]\n",
        "y_test = test[\"y_test\"]\n",
        "\n",
        "x_train = dat[\"stimuli\"]\n",
        "x_test = dat[\"stimuli_test\"]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-sizCWO-IpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "# subtract mean, divide by standard deviation, add axis \n",
        "# one-hot array \n",
        "\n",
        "x_train= x_train.astype('float32')   #currently X matrices are of data type int: need to convert here to stop python from complaining when we divide\n",
        "x_train -= np.mean(x_train)           #deduct the mean: now mean == 0\n",
        "x_train /= np.std(x_train)            #divide by the std: now std == 1\n",
        "x_train = np.expand_dims(x_train, -1) #add an extra dimension because our Conv2D layer wills it so\n",
        "\n",
        "x_test = x_test.astype('float32')     #see above\n",
        "x_test -= np.mean(x_test)\n",
        "x_test /= np.std(x_test)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "y_train -= 1\n",
        "y_test -= 1\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 8) #turn our y vectors (currently ints 0-9) into 'one-hot' vectors to match the categorical output of our network\n",
        "y_test = keras.utils.to_categorical(y_test, 8)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV1039Gp_YrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build network\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(128, 128, 1))) # A convolutional layer\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))     \n",
        "model.add(layers.Conv2D(16, (5, 5), activation='relu', kernel_initializer='he_uniform'))                            # A convolutional layer\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))                                                                  # A pooling layer to filter out some noise\n",
        "                                                                                                                # A pooling layer to filter out some noise\n",
        "model.add(layers.Flatten())   \n",
        "\n",
        "model.add(layers.Dropout(0.2))                                                                                    # A flatten layer is required to move from 2dConv to densely connected layers\n",
        "#model.add(layers.Dense(20,activation='relu'))                                                                    # This layer actually has most of our weights!\n",
        "model.add(layers.Dense(8, activation=\"softmax\"))                                                                 # Output uses another activation function and is size==output_size (==10)\n",
        "\n",
        "opt = keras.optimizers.Adam() # you can try other optimizers like Adam or Nesterov (see keras.io for documentation) or change the hyperparameters\n",
        "model.summary() \n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "# Improve model...\n",
        "#  add more convolutional layers, more kernels, add maxPooling \n",
        "#  smaller batch size\n",
        "#  add drop-out layer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKPqgVQGAILG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 30\n",
        "\n",
        "callback = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=5\n",
        ")\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks = [callback])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI6RglIYHHky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test\n",
        "\n",
        "score = model.evaluate(x_test, y_test) # generates predictions and compares them with ground truth test_y all in one easy step!\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "# 26.6 % \n",
        "# 30% \n",
        "# 33% batch size 100\n",
        "# 30% kernel size (3,3) and (5,5)\n",
        "# 33% with dropout layer "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}